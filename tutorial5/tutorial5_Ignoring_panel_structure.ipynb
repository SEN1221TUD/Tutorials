{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 5: Impact of ignoring the panel structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this tutorial we look at the impact of ignoring the panel structure when in the true Data Generating Process the panel structure is present.**<br><br>\n",
    "For this tutorial we use the same type of data as in tutorial 1, i.e. data from a two-alternative stated route choice experiment. \n",
    "But we will create more tasks per individual: 10 responses per decision maker as oppossed to 5, and more individuals (*N* = 400). Both changes will make the impact of accounting or ignoring the panel structure more pronounced.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"assets/route_choice.png\" alt=\"Route choice\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import biogeme.biogeme_logging as blog\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, bioDraws, log, MonteCarlo, exp, bioMultSum, exp\n",
    "\n",
    "# Set the number of columns to display in pandas\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biogeme optimiser and logging settings\n",
    "The file biogeme.toml contains the settings for the optimiser. In this file, we set the number of draws for estimating Mixed Logit models to 250. We use a relatively low number to avoid long estimation times.\n",
    "Also, we invoke a so-called logger which enables us to see the progress during estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger has been initialised\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logger, if it has not been initialized yet\n",
    "try:\n",
    "    logger\n",
    "except NameError:    \n",
    "    logger = blog.get_screen_logger(level=blog.INFO)\n",
    "    print('Logger has been initialised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the synthetic Panel RUM-ML data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESP</th>\n",
       "      <th>TC1</th>\n",
       "      <th>TT1</th>\n",
       "      <th>TC2</th>\n",
       "      <th>TT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RESP  TC1  TT1  TC2  TT2\n",
       "0      1    5   25    7   35\n",
       "1      1    8   20    5   40\n",
       "2      1    6   20    6   40\n",
       "3      1    7   35    5   25\n",
       "4      1    6   40    6   25\n",
       "5      1    8   25    4   35\n",
       "6      1    4   30    8   30\n",
       "7      1    4   35    8   20\n",
       "8      1    5   40    7   20\n",
       "9      1    7   30    4   30\n",
       "10     2    5   25    7   35\n",
       "11     2    8   20    5   40\n",
       "12     2    6   20    6   40\n",
       "13     2    7   35    5   25\n",
       "14     2    6   40    6   25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create np array with the choice tasks (TC1, TT1, TC2, TT2). \n",
    "# Each row is a choice task, and each column is an attribute of the choice task.\n",
    "# This design is obtained using Ngene software.\n",
    "tasks = np.array([  [5, 25, 7, 35],\n",
    "                    [8, 20, 5, 40],\n",
    "                    [6, 20, 6, 40],\n",
    "                    [7, 35, 5, 25],\n",
    "                    [6, 40, 6, 25],\n",
    "                    [8, 25, 4, 35],\n",
    "                    [4, 30, 8, 30],\n",
    "                    [4, 35, 8, 20],\n",
    "                    [5, 40, 7, 20],\n",
    "                    [7, 30, 4, 30]])\n",
    "\n",
    "# Determine the number of choice situations per respondent\n",
    "T = len(tasks)\n",
    "\n",
    "# Set the number of respondents\n",
    "N = 400\n",
    "\n",
    "# Replicate the tasks N times\n",
    "data = np.tile(tasks, (N, 1))\n",
    "\n",
    "# Create respondent IDs to add to the dataframe\n",
    "resp_id = np.expand_dims(np.repeat(np.arange(1, N+1), T), axis=1)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df = pd.DataFrame(np.concatenate((resp_id,data), axis=1), columns=['RESP','TC1', 'TT1', 'TC2', 'TT2'])\n",
    "\n",
    "# Show the first 15 rows of the dataframe\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True DGP\n",
    "Let's create (synthetic) choices with a linear-additive Panel RUM-ML. To do so, we assume:\n",
    "1. All decision makers (denoted *n*) maximise utility (decision rule)\n",
    "2. Travel cost, travel time and the label matter to the choice behaviour\n",
    "3. Travel cost and travel time are normally distributed across individuals in the population:<br>\n",
    "$\\beta_{tc_n} = \\mathcal{N}(\\mu_{tc},\\sigma_{tc})$ <br>\n",
    "$\\beta_{tt_n} = \\mathcal{N}(\\mu_{tt},\\sigma_{tt})$ <br>\n",
    "$ASC_1 = 0$   $\\forall \\textit{n}$ <br>\n",
    "$ASC_2 = 0.5$ $\\forall \\textit{n}$ <br>\n",
    "where: \n",
    "$ASC_2 = 0.5$, $\\mu_{tc} = -0.6$, $\\mu_{tt} = -0.15$, $\\sigma_{tc} = 0.15$, and $\\sigma_{tc} = 0.04$<br>\n",
    "4. Unobserved utilities are i.i.d. EV type I distributed<br>\n",
    "\n",
    "Hence, the utility function with this linear-additive Panel RUM-ML DGP is:<br><br>\n",
    "$U_{in} = V_{in} + \\varepsilon_{in}$<br>\n",
    "\n",
    "$U_{in} = ASC_{i} + \\beta_{tc_n} \\cdot x^{tc}_{in} + \\beta_{tt_n} \\cdot x^{tt}_{in} + \\varepsilon_{in}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True decision rule: Random Utility Maximisation (RUM), with parameters:\n",
      "   asc1 = 0 for all decision makers\n",
      "   asc2 = 0.5 for all decision makers\n",
      "   beta_TC is normally distributed across decision makers with location: -0.60 and standard deviation: 0.15\n",
      "   beta_TT is normally distributed across decision makers with location: -0.15 and standard deviation: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Define the true utility parameters\n",
    "asc_1 = 0\n",
    "asc_2 = 0.5\n",
    "mu_tc = -0.6\n",
    "mu_tt = -0.15\n",
    "sigma_tc = 0.15\n",
    "sigma_tt = 0.04\n",
    "\n",
    "print('True decision rule: Random Utility Maximisation (RUM), with parameters:')\n",
    "print(f'   asc1 = {asc_1} for all decision makers')\n",
    "print(f'   asc2 = {asc_2} for all decision makers')\n",
    "print(f'   beta_TC is normally distributed across decision makers with location: {mu_tc:0.2f} and standard deviation: {sigma_tc:0.2f}')\n",
    "print(f'   beta_TT is normally distributed across decision makers with location: {mu_tt:0.2f} and standard deviation: {sigma_tt:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the true taste parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESP</th>\n",
       "      <th>B_tc_n</th>\n",
       "      <th>B_tt_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525493</td>\n",
       "      <td>-0.213777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.620740</td>\n",
       "      <td>-0.173975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.620740</td>\n",
       "      <td>-0.173975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.620740</td>\n",
       "      <td>-0.173975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.620740</td>\n",
       "      <td>-0.173975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.620740</td>\n",
       "      <td>-0.173975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RESP    B_tc_n    B_tt_n\n",
       "0      1 -0.525493 -0.213777\n",
       "1      1 -0.525493 -0.213777\n",
       "2      1 -0.525493 -0.213777\n",
       "3      1 -0.525493 -0.213777\n",
       "4      1 -0.525493 -0.213777\n",
       "5      1 -0.525493 -0.213777\n",
       "6      1 -0.525493 -0.213777\n",
       "7      1 -0.525493 -0.213777\n",
       "8      1 -0.525493 -0.213777\n",
       "9      1 -0.525493 -0.213777\n",
       "10     2 -0.620740 -0.173975\n",
       "11     2 -0.620740 -0.173975\n",
       "12     2 -0.620740 -0.173975\n",
       "13     2 -0.620740 -0.173975\n",
       "14     2 -0.620740 -0.173975"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the seed to make the results replicable\n",
    "np.random.seed(42)\n",
    "\n",
    "# Draw values beta_TC and beta_TT for each decision maker\n",
    "beta_tcn = np.random.normal(mu_tc, sigma_tc, N)\n",
    "beta_ttn = np.random.normal(mu_tt, sigma_tt, N)\n",
    "\n",
    "# Replicate the values of beta_TC and beta_TT for each choice situation\n",
    "beta_tc = np.repeat(beta_tcn,T)\n",
    "beta_tt = np.repeat(beta_ttn,T)\n",
    "\n",
    "# Show the panel structure\n",
    "true_betas = pd.DataFrame({'RESP':df['RESP'],'B_tc_n': beta_tc, 'B_tt_n': beta_tt})\n",
    "true_betas.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`--> Note that we assume an individual has stable taste parameters across choice tasks.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify the distribution of beta_tc and beta_tt using a plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].hist(beta_tcn, bins=15, color='blue', alpha=0.7, edgecolor='black')\n",
    "ax[0].set_title(f'True distribution of $\\\\beta_{{TC}}$ in the sample with\\n mean = {np.mean(beta_tcn):.2f}, std = {np.std(beta_tcn):.2f}')\n",
    "ax[1].hist(beta_ttn, bins=15, color='blue', alpha=0.7, edgecolor='black')\n",
    "ax[1].set_title(f'True distribution of $\\\\beta_{{TT}}$ in the sample with\\n mean = {np.mean(beta_ttn):.2f}, std = {np.std(beta_ttn):.2f}')\n",
    "\n",
    "ax[0].set_xlabel('$\\\\beta_{TC}$')\n",
    "ax[1].set_xlabel('$\\\\beta_{TT}$')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the choices using the true DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESP</th>\n",
       "      <th>TC1</th>\n",
       "      <th>TT1</th>\n",
       "      <th>TC2</th>\n",
       "      <th>TT2</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>epsilon1</th>\n",
       "      <th>epsilon2</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>-7.971892</td>\n",
       "      <td>-10.660649</td>\n",
       "      <td>0.956226</td>\n",
       "      <td>-0.258462</td>\n",
       "      <td>-7.015666</td>\n",
       "      <td>-10.919111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>-8.479485</td>\n",
       "      <td>-10.678549</td>\n",
       "      <td>-0.568489</td>\n",
       "      <td>2.045503</td>\n",
       "      <td>-9.047974</td>\n",
       "      <td>-8.633046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>-7.428499</td>\n",
       "      <td>-11.204042</td>\n",
       "      <td>3.277835</td>\n",
       "      <td>1.019855</td>\n",
       "      <td>-4.150664</td>\n",
       "      <td>-10.184187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>-11.160649</td>\n",
       "      <td>-7.471892</td>\n",
       "      <td>0.097603</td>\n",
       "      <td>0.274050</td>\n",
       "      <td>-11.063046</td>\n",
       "      <td>-7.197842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>-11.704042</td>\n",
       "      <td>-7.997385</td>\n",
       "      <td>1.341794</td>\n",
       "      <td>0.185042</td>\n",
       "      <td>-10.362247</td>\n",
       "      <td>-7.812342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RESP  TC1  TT1  TC2  TT2         V1         V2  epsilon1  epsilon2  \\\n",
       "0     1    5   25    7   35  -7.971892 -10.660649  0.956226 -0.258462   \n",
       "1     1    8   20    5   40  -8.479485 -10.678549 -0.568489  2.045503   \n",
       "2     1    6   20    6   40  -7.428499 -11.204042  3.277835  1.019855   \n",
       "3     1    7   35    5   25 -11.160649  -7.471892  0.097603  0.274050   \n",
       "4     1    6   40    6   25 -11.704042  -7.997385  1.341794  0.185042   \n",
       "\n",
       "          U1         U2  CHOICE  \n",
       "0  -7.015666 -10.919111       1  \n",
       "1  -9.047974  -8.633046       2  \n",
       "2  -4.150664 -10.184187       1  \n",
       "3 -11.063046  -7.197842       2  \n",
       "4 -10.362247  -7.812342       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the utilities given the DGP\n",
    "df['V1'] = asc_1 + beta_tc * df['TC1'] + beta_tt * df['TT1'] \n",
    "df['V2'] = asc_2 + beta_tc * df['TC2'] + beta_tt * df['TT2']\n",
    "\n",
    "# Add the error terms\n",
    "df['epsilon1'] = np.random.gumbel(size=len(df))\n",
    "df['epsilon2'] = np.random.gumbel(size=len(df))\n",
    "\n",
    "# Compute the total utility\n",
    "df['U1'] = df['V1'] + df['epsilon1']\n",
    "df['U2'] = df['V2'] + df['epsilon2']\n",
    "\n",
    "# Identify the chosen alternative\n",
    "df['CHOICE'] = np.nan\n",
    "df.loc[df['U1'] > df['U2'], 'CHOICE'] = 1\n",
    "df.loc[df['U2'] > df['U1'], 'CHOICE'] = 2\n",
    "\n",
    "# Convert the chosen alternative to an integer (optional)\n",
    "df['CHOICE'] = df['CHOICE'].astype(int)\n",
    "\n",
    "# Save the data in a csv file\n",
    "data_path =  Path(f'data/synthetic_VTTdata_tutorial3.dat')\n",
    "df[['RESP','TC1', 'TT1', 'TC2', 'TT2','CHOICE']].to_csv(data_path, sep=',', index=False)\n",
    "\n",
    "# Show the first rows\n",
    "df.head()\n",
    "# df.value_counts('CHOICE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`--> We have created a data set in which the DGP is linear-additive Panel RUM-ML`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Recovery of the model parameters\n",
    "Now, let's have a look what happens if we estimate a discrete choice model that **perfectly** aligns with the DGP. When we do so, we expect we are able to accurately recover the true parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a biogeme database in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations per individual: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHOICE_0</th>\n",
       "      <th>TC1_0</th>\n",
       "      <th>TC2_0</th>\n",
       "      <th>TT1_0</th>\n",
       "      <th>TT2_0</th>\n",
       "      <th>CHOICE_1</th>\n",
       "      <th>TC1_1</th>\n",
       "      <th>TC2_1</th>\n",
       "      <th>TT1_1</th>\n",
       "      <th>TT2_1</th>\n",
       "      <th>CHOICE_2</th>\n",
       "      <th>TC1_2</th>\n",
       "      <th>TC2_2</th>\n",
       "      <th>TT1_2</th>\n",
       "      <th>TT2_2</th>\n",
       "      <th>CHOICE_3</th>\n",
       "      <th>TC1_3</th>\n",
       "      <th>TC2_3</th>\n",
       "      <th>TT1_3</th>\n",
       "      <th>TT2_3</th>\n",
       "      <th>CHOICE_4</th>\n",
       "      <th>TC1_4</th>\n",
       "      <th>TC2_4</th>\n",
       "      <th>TT1_4</th>\n",
       "      <th>TT2_4</th>\n",
       "      <th>CHOICE_5</th>\n",
       "      <th>TC1_5</th>\n",
       "      <th>TC2_5</th>\n",
       "      <th>TT1_5</th>\n",
       "      <th>TT2_5</th>\n",
       "      <th>CHOICE_6</th>\n",
       "      <th>TC1_6</th>\n",
       "      <th>TC2_6</th>\n",
       "      <th>TT1_6</th>\n",
       "      <th>TT2_6</th>\n",
       "      <th>CHOICE_7</th>\n",
       "      <th>TC1_7</th>\n",
       "      <th>TC2_7</th>\n",
       "      <th>TT1_7</th>\n",
       "      <th>TT2_7</th>\n",
       "      <th>CHOICE_8</th>\n",
       "      <th>TC1_8</th>\n",
       "      <th>TC2_8</th>\n",
       "      <th>TT1_8</th>\n",
       "      <th>TT2_8</th>\n",
       "      <th>CHOICE_9</th>\n",
       "      <th>TC1_9</th>\n",
       "      <th>TC2_9</th>\n",
       "      <th>TT1_9</th>\n",
       "      <th>TT2_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CHOICE_0  TC1_0  TC2_0  TT1_0  TT2_0  CHOICE_1  TC1_1  TC2_1  TT1_1  \\\n",
       "RESP                                                                        \n",
       "1            1      5      7     25     35         2      8      5     20   \n",
       "2            1      7      4     30     30         2      5      7     40   \n",
       "3            2      7      4     30     30         2      5      7     40   \n",
       "4            1      4      8     30     30         2      7      4     30   \n",
       "5            2      7      4     30     30         2      5      7     40   \n",
       "\n",
       "      TT2_1  CHOICE_2  TC1_2  TC2_2  TT1_2  TT2_2  CHOICE_3  TC1_3  TC2_3  \\\n",
       "RESP                                                                        \n",
       "1        40         1      6      6     20     40         2      7      5   \n",
       "2        20         1      4      8     30     30         2      8      4   \n",
       "3        20         1      4      8     35     20         2      4      8   \n",
       "4        30         2      5      7     40     20         2      4      8   \n",
       "5        20         2      4      8     35     20         1      4      8   \n",
       "\n",
       "      TT1_3  TT2_3  CHOICE_4  TC1_4  TC2_4  TT1_4  TT2_4  CHOICE_5  TC1_5  \\\n",
       "RESP                                                                        \n",
       "1        35     25         2      6      6     40     25         1      8   \n",
       "2        25     35         2      4      8     35     20         2      7   \n",
       "3        30     30         2      8      4     25     35         2      6   \n",
       "4        35     20         2      8      4     25     35         1      6   \n",
       "5        30     30         1      8      4     25     35         2      7   \n",
       "\n",
       "      TC2_5  TT1_5  TT2_5  CHOICE_6  TC1_6  TC2_6  TT1_6  TT2_6  CHOICE_7  \\\n",
       "RESP                                                                        \n",
       "1         4     25     35         1      4      8     30     30         2   \n",
       "2         5     35     25         1      6      6     20     40         1   \n",
       "3         6     40     25         1      6      6     20     40         1   \n",
       "4         6     20     40         2      7      5     35     25         2   \n",
       "5         5     35     25         1      6      6     20     40         2   \n",
       "\n",
       "      TC1_7  TC2_7  TT1_7  TT2_7  CHOICE_8  TC1_8  TC2_8  TT1_8  TT2_8  \\\n",
       "RESP                                                                     \n",
       "1         4      8     35     20         2      5      7     40     20   \n",
       "2         8      5     20     40         1      5      7     25     35   \n",
       "3         8      5     20     40         1      5      7     25     35   \n",
       "4         6      6     40     25         1      8      5     20     40   \n",
       "5         8      5     20     40         1      5      7     25     35   \n",
       "\n",
       "      CHOICE_9  TC1_9  TC2_9  TT1_9  TT2_9  \n",
       "RESP                                        \n",
       "1            2      7      4     30     30  \n",
       "2            2      6      6     40     25  \n",
       "3            2      7      5     35     25  \n",
       "4            1      5      7     25     35  \n",
       "5            2      6      6     40     25  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Biogeme database object\n",
    "biodata = db.Database('synthetic_VTTdata_tutorial3', df[['RESP','TC1', 'TT1', 'TC2', 'TT2','CHOICE']].copy())\n",
    "\n",
    "# Tell Biogeme which variable is the identifier of the individuals\n",
    "biodata.panel('RESP')\n",
    "\n",
    "# Calculate the number of observations per individual\n",
    "obs_per_ind = biodata.data['RESP'].value_counts().unique()[0]\n",
    "print(f'Number of observations per individual: {obs_per_ind}')\n",
    "\n",
    "# Use biogeme's \"generateFlatPanelDataFrame to create a wide database in which each row corresponds to one individual\n",
    "df_wide = biodata.generate_flat_panel_dataframe(identical_columns=None)\n",
    "\n",
    "# Rename the columns, such that they run from columnname_{0} to columnname_{n} \n",
    "renumbered_columns = {col: f'{col.split(\"_\")[1]}_{int(col.split(\"_\")[0])-1}' if len(col.split(\"_\")) == 2 else col for col in df_wide.columns}\n",
    "\n",
    "# Rename the columns using the dictionary\n",
    "df_wide.rename(columns=renumbered_columns, inplace=True)\n",
    "\n",
    "# Create Biogeme database object\n",
    "biodata_wide = db.Database('synthetic_VTTdata_tutorial3_wide', df_wide)\n",
    "biodata_wide.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the discrete choice model that does capture the panel structure\n",
    "The true DGP is a linear-additive Panel RUM-ML. Therefore, we first estimate this model.<br>\n",
    "Note that estimating this model may take a couple of minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Panel RUM-ML model with normally distributed parameters'\n",
    "\n",
    "# Parameters definition enabling the construction of random parameters\n",
    "ASC1       = Beta('ASC1',         0, None, None, 1)\n",
    "ASC2       = Beta('ASC2',         0, None, None, 0)\n",
    "mu_tc      = Beta('mu_tc',     -0.1, None, None, 0)    \n",
    "mu_tt      = Beta('mu_tt',     -0.1, None, None, 0)    \n",
    "sigma_tc   = Beta('sigma_tc ',  0.1, None, None, 0)\n",
    "sigma_tt   = Beta('sigma_tt ',  0.1, None, None, 0)\n",
    "\n",
    "# Construction of random parameters   \n",
    "B_tc_rnd = mu_tc   + sigma_tc   * bioDraws('B_tc_rnd', 'NORMAL_HALTON2')\n",
    "B_tt_rnd = mu_tt   + sigma_tt   * bioDraws('B_tt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions\n",
    "# Note that we use list comprehension to create a list of utility functions for all observations of an individual \n",
    "V1 = [(ASC1 + B_tc_rnd * Variable(f'TC1_{q}') + B_tt_rnd * Variable(f'TT1_{q}')) for q in range(obs_per_ind)]\n",
    "V2 = [(ASC2 + B_tc_rnd * Variable(f'TC2_{q}') + B_tt_rnd * Variable(f'TT2_{q}')) for q in range(obs_per_ind)]\n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "# Note that we use list comprehension to create a list of dictionaries\n",
    "V = [{1: V1[q], 2: V2[q]} for q in range(obs_per_ind)]\n",
    "           \n",
    "# Create a dictionary to describe the availability conditions of each alternative\n",
    "av = {1:1, 2:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the model and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default values of the Biogeme parameters are used. \n",
      "File biogeme.toml has been created \n",
      "As the model is rather complex, we cancel the calculation of second derivatives. If you want to control the parameters, change the name of the algorithm in the TOML file from \"automatic\" to \"simple_bounds\" \n",
      "The number of draws (100) is low. The results may not be meaningful. \n",
      "As the model is rather complex, we cancel the calculation of second derivatives. If you want to control the parameters, change the name of the algorithm in the TOML file from \"automatic\" to \"simple_bounds\" \n",
      "Optimization algorithm: hybrid Newton/BFGS with simple bounds [simple_bounds] \n",
      "** Optimization: BFGS with trust region for simple bounds \n",
      "Iter.            ASC2           mu_tc           mu_tt       sigma_tc        sigma_tt      Function    Relgrad   Radius      Rho      \n",
      "    0               0            -0.1            -0.1             0.1             0.1      2.1e+03       0.96      0.5     -0.3    - \n",
      "    1               0            -0.1            -0.1             0.1             0.1      2.1e+03       0.96     0.25    -0.47    - \n",
      "    2               0            -0.1            -0.1             0.1             0.1      2.1e+03       0.96     0.12    -0.82    - \n",
      "    3               0            -0.1            -0.1             0.1             0.1      2.1e+03       0.96    0.062     -1.3    - \n",
      "    4           0.062           -0.16          -0.038            0.16           0.038        2e+03        2.9    0.062     0.25    + \n",
      "    5           0.067           -0.17            -0.1            0.16             0.1        2e+03       0.76    0.062     0.29    + \n",
      "    6           0.078           -0.23          -0.093            0.17           0.072      1.8e+03       0.52     0.62      1.2   ++ \n",
      "    7           0.078           -0.23          -0.093            0.17           0.072      1.8e+03       0.52     0.31    -0.35    - \n",
      "    8           0.078           -0.23          -0.093            0.17           0.072      1.8e+03       0.52     0.16    0.021    - \n",
      "    9            0.12           -0.39           -0.14             0.2          -0.051      1.7e+03       0.49     0.16     0.69    + \n",
      "   10            0.12           -0.39           -0.14             0.2          -0.051      1.7e+03       0.49    0.078    0.084    - \n",
      "   11            0.12           -0.39           -0.14             0.2          -0.051      1.7e+03       0.49    0.039     -2.3    - \n",
      "   12            0.12           -0.39           -0.14             0.2          -0.051      1.7e+03       0.49     0.02    -0.69    - \n",
      "   13            0.14           -0.41           -0.16            0.18          -0.032      1.7e+03       0.65     0.02     0.33    + \n",
      "   14            0.15           -0.43           -0.14            0.18          -0.049      1.7e+03       0.43     0.02     0.77    + \n",
      "   15            0.17           -0.45           -0.15            0.16          -0.029      1.6e+03       0.42      0.2        1   ++ \n",
      "   16            0.17           -0.45           -0.15            0.16          -0.029      1.6e+03       0.42    0.098     -2.6    - \n",
      "   17            0.17           -0.45           -0.15            0.16          -0.029      1.6e+03       0.42    0.049     -3.7    - \n",
      "   18            0.17           -0.45           -0.15            0.16          -0.029      1.6e+03       0.42    0.024    -0.65    - \n",
      "   19            0.17           -0.46           -0.13            0.16          -0.033      1.6e+03       0.36    0.024     0.33    + \n",
      "   20            0.19           -0.48           -0.14            0.15         -0.0086      1.6e+03       0.17    0.024     0.64    + \n",
      "   21             0.2            -0.5           -0.14            0.14          -0.033      1.6e+03       0.14    0.024     0.72    + \n",
      "   22            0.23           -0.53           -0.15            0.13          -0.018      1.6e+03       0.35    0.024     0.36    + \n",
      "   23            0.23           -0.53           -0.15            0.13          -0.018      1.6e+03       0.35    0.012     -0.3    - \n",
      "   24            0.23           -0.53           -0.14            0.13           -0.03      1.6e+03       0.18    0.012     0.66    + \n",
      "   25            0.24           -0.54           -0.15            0.12           -0.03      1.6e+03      0.065     0.12     0.94   ++ \n",
      "   26            0.24           -0.54           -0.15            0.12           -0.03      1.6e+03      0.065    0.061     -1.1    - \n",
      "   27            0.24           -0.54           -0.15            0.12           -0.03      1.6e+03      0.065    0.031    -0.28    - \n",
      "   28            0.27           -0.55           -0.14            0.11          -0.022      1.6e+03       0.29    0.031     0.27    + \n",
      "   29            0.31           -0.56           -0.15           0.094          -0.027      1.6e+03       0.23    0.031     0.55    + \n",
      "   30            0.31           -0.56           -0.15           0.094          -0.027      1.6e+03       0.23    0.015    -0.54    - \n",
      "   31            0.31           -0.56           -0.15           0.094          -0.042      1.6e+03       0.16    0.015      0.2    + \n",
      "   32            0.33           -0.56           -0.14           0.088           -0.03      1.6e+03       0.11    0.015     0.69    + \n",
      "   33            0.33           -0.56           -0.14           0.088           -0.03      1.6e+03       0.11   0.0076    -0.25    - \n",
      "   34            0.33           -0.55           -0.15           0.088          -0.036      1.6e+03      0.083   0.0076     0.45    + \n",
      "   35            0.34           -0.55           -0.15           0.086          -0.038      1.6e+03      0.087   0.0076     0.54    + \n",
      "   36            0.35           -0.55           -0.15           0.083          -0.032      1.6e+03      0.059   0.0076     0.68    + \n",
      "   37            0.36           -0.55           -0.15           0.082          -0.038      1.6e+03      0.039   0.0076     0.85    + \n",
      "   38            0.36           -0.55           -0.15            0.08          -0.033      1.6e+03      0.054    0.076      0.9   ++ \n",
      "   39            0.44           -0.55           -0.15           0.066          -0.043      1.6e+03      0.066    0.076      0.7    + \n",
      "   40            0.44           -0.55           -0.15           0.066          -0.043      1.6e+03      0.066    0.038     -1.2    - \n",
      "   41            0.44           -0.55           -0.15           0.066          -0.043      1.6e+03      0.066    0.019     -1.2    - \n",
      "   42            0.44           -0.55           -0.15           0.066          -0.043      1.6e+03      0.066   0.0095     -1.5    - \n",
      "   43            0.45           -0.56           -0.15           0.062          -0.034      1.6e+03      0.079   0.0095     0.18    + \n",
      "   44            0.46           -0.56           -0.15           0.064          -0.039      1.6e+03      0.058   0.0095     0.85    + \n",
      "   45            0.46           -0.56           -0.15           0.064          -0.039      1.6e+03      0.058   0.0048    -0.19    - \n",
      "   46            0.46           -0.56           -0.15           0.064          -0.039      1.6e+03      0.058   0.0024   -0.056    - \n",
      "   47            0.46           -0.56           -0.15           0.064          -0.041      1.6e+03      0.042   0.0024     0.28    + \n",
      "   48            0.46           -0.56           -0.15           0.064          -0.039      1.6e+03      0.016    0.024     0.97   ++ \n",
      "   49            0.49           -0.56           -0.15           0.067          -0.042      1.6e+03      0.044    0.024     0.78    + \n",
      "   50            0.51           -0.56           -0.15            0.07          -0.036      1.6e+03        0.1    0.024     0.12    + \n",
      "   51            0.54           -0.57           -0.15           0.074           -0.04      1.6e+03      0.018    0.024     0.53    + \n",
      "   52            0.54           -0.57           -0.15           0.074           -0.04      1.6e+03      0.018    0.012    -0.85    - \n",
      "   53            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03      0.025    0.012     0.33    + \n",
      "   54            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03      0.025    0.006      -10    - \n",
      "   55            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03      0.025    0.003     -3.5    - \n",
      "   56            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03      0.025   0.0015    -0.82    - \n",
      "   57            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03      0.018   0.0015     0.33    + \n",
      "   58            0.54           -0.56           -0.15           0.073          -0.038      1.6e+03     0.0092   0.0015     0.71    + \n",
      "   59            0.54           -0.56           -0.15           0.073          -0.038      1.6e+03     0.0092  0.00075    -0.35    - \n",
      "   60            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0055  0.00075     0.55    + \n",
      "   61            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0055  0.00037     -0.7    - \n",
      "   62            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0063  0.00037     0.17    + \n",
      "   63            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0012   0.0037     0.92   ++ \n",
      "   64            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0012   0.0019       -2    - \n",
      "   65            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0012  0.00093     -1.9    - \n",
      "   66            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0012  0.00047     -2.6    - \n",
      "   67            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0012  0.00023    -0.35    - \n",
      "   68            0.54           -0.56           -0.15           0.074          -0.039      1.6e+03     0.0025  0.00023     0.24    + \n",
      "   69            0.54           -0.56           -0.15           0.074          -0.039      1.6e+03    0.00071   0.0023     0.97   ++ \n",
      "   70            0.54           -0.56           -0.15           0.072          -0.039      1.6e+03    0.00097   0.0023     0.25    + \n",
      "   71            0.54           -0.56           -0.15           0.072          -0.039      1.6e+03    0.00097   0.0012    -0.13    - \n",
      "   72            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0013   0.0012     0.55    + \n",
      "   73            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0013  0.00058     -3.3    - \n",
      "   74            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0013  0.00029     -1.5    - \n",
      "   75            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0013  0.00015    0.089    - \n",
      "   76            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03    0.00071  0.00015     0.41    + \n",
      "   77            0.54           -0.56           -0.15           0.073          -0.039      1.6e+03     0.0001  0.00015     0.79    + \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated parameters:\t5\n",
      "Sample size:\t400\n",
      "Excluded observations:\t0\n",
      "Null log likelihood:\t-2772.589\n",
      "Init log likelihood:\t-2129.086\n",
      "Final log likelihood:\t-1589.603\n",
      "Likelihood ratio test for the null model:\t2365.972\n",
      "Rho-square for the null model:\t0.427\n",
      "Rho-square-bar for the null model:\t0.425\n",
      "Likelihood ratio test for the init. model:\t1078.966\n",
      "Rho-square for the init. model:\t0.253\n",
      "Rho-square-bar for the init. model:\t0.251\n",
      "Akaike Information Criterion:\t3189.206\n",
      "Bayesian Information Criterion:\t3209.163\n",
      "Final gradient norm:\t2.4458E-01\n",
      "Number of draws:\t100\n",
      "Draws generation time:\t0:00:00.035900\n",
      "Types of draws:\t['B_tc_rnd: NORMAL_HALTON2', 'B_tt_rnd: NORMAL_HALTON2']\n",
      "Nbr of threads:\t10\n",
      "\n",
      "              Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC2       0.541310      0.045252    11.961994  0.000000e+00\n",
      "mu_tc     -0.562936      0.020155   -27.930600  0.000000e+00\n",
      "mu_tt     -0.151769      0.005333   -28.456079  0.000000e+00\n",
      "sigma_tc   0.073319      0.034223     2.142379  3.216298e-02\n",
      "sigma_tt  -0.039167      0.006998    -5.596601  2.185955e-08\n"
     ]
    }
   ],
   "source": [
    "# Estimate the model\n",
    "\n",
    "# The conditional probability of the chosen alternative is a logit\n",
    "condProb = [models.loglogit(V[q], av, Variable(f'CHOICE_{q}')) for q in range(obs_per_ind)] \n",
    "\n",
    "# Take the product of the conditional probabilities\n",
    "condprobIndiv = exp(bioMultSum(condProb))   # exp to convert from logP to P again\n",
    "\n",
    "# The unconditional probability is obtained by simulation\n",
    "uncondProb = MonteCarlo(condprobIndiv)\n",
    "\n",
    "# The Log-likelihood is the log of the unconditional probability\n",
    "LL = log(uncondProb)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata_wide , LL, number_of_draws=100)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.save_iterations = False\n",
    "biogeme.modelName = model_name\n",
    "                                \n",
    "# Compute the null loglikelihood for reporting\n",
    "# Note that we need to compute it manually, as biogeme does not do this for panel data\n",
    "biogeme.nullLogLike = len(biodata_wide.data)*np.log(1/2)*obs_per_ind\n",
    "\n",
    "# Estimate the parameters and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.print_general_statistics())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Based on the above estimation results, we can make a couple of observations:`<br><br>\n",
    "`1. The true parameters are recovered well. The estimated parameters are close to the true values, i.e. withint est ± 1.96 * S.E.`<br><br>\n",
    "`2. The standard errors are fairly small, which is expected given the sample size.`<br><br>\n",
    "`3. The model seems properly converged, as we see a descent rho square and no suspiciously large S.E. or parameter estimates.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The effect of ignoring the panel structure\n",
    "Now we are going to estimate a linear-additive RUM-MNL model. The utility function of this model is well specified (i.e. it matches the true DGP). But the MNL model does not account for panel structures (or the heterogeneity). That is, it cannot see that *N* individuals made *T* choices. Instead, it treats every observation as a new independent data point. Hence, it ignores the fact that individuals tastes are correlated across choice observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate a linear-additive RUM-MNL model (i.e. a model that does not capture the panel structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Biogeme parameters read from biogeme.toml. \n",
      "As the model is not too complex, we activate the calculation of second derivatives. If you want to change it, change the name of the algorithm in the TOML file from \"automatic\" to \"simple_bounds\" \n",
      "As the model is not too complex, we activate the calculation of second derivatives. If you want to change it, change the name of the algorithm in the TOML file from \"automatic\" to \"simple_bounds\" \n",
      "Optimization algorithm: hybrid Newton/BFGS with simple bounds [simple_bounds] \n",
      "** Optimization: Newton with trust region for simple bounds \n",
      "Iter.            ASC2            B_TC            B_TT     Function    Relgrad   Radius      Rho      \n",
      "    0            0.31           -0.39            -0.1      1.7e+03       0.87       10      1.1   ++ \n",
      "    1            0.46           -0.51           -0.13      1.6e+03       0.14    1e+02      1.1   ++ \n",
      "    2             0.5           -0.54           -0.14      1.6e+03     0.0064    1e+03        1   ++ \n",
      "    3             0.5           -0.54           -0.14      1.6e+03    1.6e-05    1e+03        1   ++ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model MNL model\n",
      "Nbr of parameters:\t\t3\n",
      "Sample size:\t\t\t4000\n",
      "Excluded data:\t\t\t0\n",
      "Null log likelihood:\t\t-2772.589\n",
      "Final log likelihood:\t\t-1609.389\n",
      "Likelihood ratio test (null):\t\t2326.4\n",
      "Rho square (null):\t\t\t0.42\n",
      "Rho bar square (null):\t\t\t0.418\n",
      "Akaike Information Criterion:\t3224.777\n",
      "Bayesian Information Criterion:\t3243.659\n",
      "\n",
      "         Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC2  0.502644      0.045858    10.960796           0.0\n",
      "B_TC -0.543329      0.018170   -29.902751           0.0\n",
      "B_TT -0.141622      0.004033   -35.113956           0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the Biogeme database object\n",
    "biodata = db.Database('synthetic_VTTdata_tutorial4', df[['RESP','TC1', 'TT1', 'TC2', 'TT2','CHOICE']])\n",
    "\n",
    "# We create Variable objects for each of the variables in the data set that we want to use in the model\n",
    "TT1  = Variable('TT1')\n",
    "TC1  = Variable('TC1')\n",
    "TT2  = Variable('TT2')\n",
    "TC2  = Variable('TC2')\n",
    "CHOICE = Variable('CHOICE')\n",
    "\n",
    "# Define the parameters to be estimated\n",
    "ASC1 = Beta('ASC1', 0, None, None, 1)\n",
    "ASC2 = Beta('ASC2', 0, None, None, 0)\n",
    "B_TT = Beta('B_TT', 0, None, None, 0)\n",
    "B_TC = Beta('B_TC', 0, None, None, 0)\n",
    "\n",
    "# Define the utility functions\n",
    "V1 = ASC1 + B_TT * TT1 + B_TC * TC1\n",
    "V2 = ASC2 + B_TT * TT2 + B_TC * TC2\n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: V1, 2: V2}\n",
    "    \n",
    "# Create a dictionary called av to describe the availability conditions of each alternative, where 1 indicates that the alternative is available, and 0 indicates that the alternative is not available.\n",
    "av = {1: 1, 2: 1} \n",
    "\n",
    "# Define the choice model: The function models.logit() computes the MNL choice probabilities of the chosen alternative given the V. \n",
    "prob = models.logit(V, av, CHOICE)\n",
    "\n",
    "# Define the log-likelihood   \n",
    "LL = log(prob)\n",
    "\n",
    "# Create the Biogeme object containing the object database and the formula for the contribution to the log-likelihood of each row using the following syntax:\n",
    "biogeme = bio.BIOGEME(biodata, LL)\n",
    "\n",
    "# The following syntax passes the name of the model:\n",
    "model_name = 'MNL model'\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Some object settings regarding whether to save the results and outputs \n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.save_iterations = False\n",
    "\n",
    "# Syntax to calculate the null log-likelihood. The null-log-likelihood is used to compute the rho-square \n",
    "biogeme.calculate_null_loglikelihood(av)\n",
    "\n",
    "# This line starts the estimation and returns the results object.\n",
    "results_MNL = biogeme.estimate()\n",
    "\n",
    "# Print the estimation statistics\n",
    "print(results_MNL.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat_MNL = results_MNL.get_estimated_parameters()\n",
    "print(beta_hat_MNL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of standard errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASC2</th>\n",
       "      <td>0.986787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_TC</th>\n",
       "      <td>1.109243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_TT</th>\n",
       "      <td>1.322385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ratio of standard errors\n",
       "ASC2                  0.986787\n",
       "B_TC                  1.109243\n",
       "B_TT                  1.322385"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the ratio of the standard errors for comparison\n",
    "ratio_SE = beta_hat['Rob. Std err'][0:3].values/beta_hat_MNL['Rob. Std err'].values\n",
    "\n",
    "# Show in a dataframe\n",
    "pd.DataFrame(ratio_SE, columns=['Ratio of standard errors'], index=beta_hat_MNL.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`--> We can make a couple of observations:`<br><br>\n",
    "`1. The standard errors of the MNL model are smaller than those from the Panel ML model (except for the ASC). This result was to be expected since the MNL model overestimates the number of iid data points in the data set because it is blind to the panel structure.`<br><br>\n",
    "`2. The estimates of the MNL model seem pretty okay. One reason why we do not see more pronounced bias in th estimates is that the normal distribution is symmetric. But more careful inspection shows that B_tt is actually biased`<br><br>\n",
    "`3. The Final log-likelihood of the Panel ML model is higher that of the MNL model. This is expected because the former is matches the true DGP, while the latter does not`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sen1221env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
